---
layout: post
title:  "하코사 세미나_ 웹 크롤링 넌 누구!? by 크로스핏"
icon:  heart-o
category: java

---

웹 크롤링에 대하여 

radiohead.github.io ==> 블로그 

웹사이트에서 원하는 정보를 수집하는 것을 크롤링!! 이라함.

웹 크롤링 == 웹 스크래핑

사용 예시!!

1.실시간 검색어 순위 
2.특정 텍스트가 포함된 뉴스
3.해외 축구 알림

빅데이터 서비스를 위해서 크롤링이 필요하다.

해당 도메인/robots.txt를 입력을 통해 크롤링 가능 한지에 대한 규약을 확인 해야 함
allow/ disallow의 확인 

--> 범죄자 되기 싫으면 하지마세요, 상업 목적gg

크롤링을 하려면 파이썬 노드를 쓰는데 

파이썬이 최고임!!!!!!
cheerio 종휴 찾아 봐요 

노드 의 특징을 이용한 데이터의 빠른 처리 하나의 플랫폼으로 풀스택 개발 가능 왜! 노드는 서버사이드 개발 가능 
그러나 노드는 프론트 사이드랭귀지 임!!! 
(키워드: 노드, express,npm)
노드 이용시 npm을 이용하여 모듈을 사용하자!!

---> 현 세미나에서는 es6 문법을 사용함 
const , let,  arrow fx

request cheerio cheerio-cli 를 이용하여 제이쿼리 정제 가능 하게 함 
fs 모듈로 파일을 다룸 읽고 쓰기 저장 가능 

세미나에서 크롤링에서의 모듈 
fs를 이용한 파일의 읽고 쓰고 저장 
request cheerio cheerio-cli ==> 데이터 크롤링 > 데이터 가공



크롤링 방법  

1.웹사이트의 구조를 파악
개발자 도구로 사이ㄷ트의 공통점 및 구조의 파악 

2. request, cheerio로 사이트 전체를 가져옴
그러나 노드는 euc-kr을 지원 안하여 모듈을 찾아서 설치(icov)

3.fs를 이용하여 쓰기 및 저장 
json(자바스크립트 이용 스트링으로 저장 한다.) 

tip 파일 표현시  예시1
자바스크립트를 이용!
오브젝트.키 벨류를 이용

===> 이러한 데이터들은 모듈과 각종 툴을 이용하여 정제가 가능 합니다!!!!

즉,크롤링한 데이터들을 json type으로 저장하고 그러한 정보를 이용하여 
정제 및 표현 


두개 이상의 유알엘일 때 예시 노드 익스프레스 이용.


tip.  url 사용시 여러번 요청하게 된다

그래서 크롤링한 데이터를 json으로 저장한 후 사용하게 되면 

1번의 요청으로 데이터의 처리가 가능하다!!










 